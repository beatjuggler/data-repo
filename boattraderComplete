import requests
from bs4 import BeautifulSoup, SoupStrainer
import bs4
import urllib2
import csv



def scraper(search_link):
    data = [] #Initialize outside of the results page, inherits from for loop

    while True:
        r = requests.get(search_link)
        raw_html = r.text
        soup = BeautifulSoup(raw_html, 'html.parser')

        search_page_buttons = soup.find_all('a', {'title': 'Next Page'})
        divTag = soup.find_all('div', {'class': 'ad-title'})

        last_page = True

        for index, tag in enumerate(divTag):
            aTags = tag.find_all('a')

            for url in aTags:
                url = url.get('href')
                concat_link = "http://www.boattrader.com" + url
##                print index +1, concat_link

                soup = BeautifulSoup(urllib2.urlopen(concat_link).read())
                make = soup.find_all('span', {'class':'bd-make'})
                model = soup.find_all('span', {'class':'bd-model'})
##                print "Make: " + make[0].text + " Model: " + model[0].text

                phone = soup.find_all('div', {'class':'contact'})
##                print "Phone Number: " + phone[0].text

                price = soup.find_all('span', {'class':'bd-price'})
##                print "Price: " + price[0].text.strip() + '\n'

                data.append([concat_link, make, model, phone, price])#adds each listing's values to a row for each iteration of for loop
                
            if index == 24:
                for page_url in search_page_buttons:
                    page_url = "http://www.boattrader.com" + page_url.get('href')
                    search_link = page_url
                last_page = False
##                print 'Next Page of Results:' + '\n'
        if last_page:
            return data#returns data list to method level

def csv_writer(data, path):
    with open(path, 'wb') as csv_file:
        writer = csv.writer(csv_file, delimiter=',')
##    csv_file = csv.writer(open('boatsoutput.csv', 'wb'))
        for item in data:
            writer.writerow(item)


if __name__ == '__main__':

    search_link = "http://www.boattrader.com/search-results/NewOrUsed-any/Type-any/Category-all/Zip-10001/Radius-100/Make-MASTERCRAFT/Sort-Length:DESC"
##    search_link = raw_input('Copy and paste the URL after doing a search: ')
    csv_data = scraper(search_link) #assigns data list from scraper method to csv_data var
    path = "boatsoutput.csv"
    csv_writer(csv_data,path)#passes to csv_writer method the data, path parameters
    print 'File Done'
